#!/usr/bin/env python3
"""
Exercise 2: Generate Synthetic Dataset
Module 3: Isaac Sim - Photorealistic Simulation

Learning Objectives:
- Generate synthetic RGB and depth images with ground truth annotations
- Apply domain randomization techniques
- Validate dataset quality and generation rate
- FR-003: Generate synthetic labeled datasets
- FR-004: Apply domain randomization capabilities
- SC-001: Generate 1000+ labeled images within 1 hour
- SC-007: Achieve >85% perception accuracy with generated datasets

Usage:
    python3 ex2-generate-dataset.py
    python3 ex2-generate-dataset.py --num-images 1000 --output-dir datasets/my_dataset
    python3 ex2-generate-dataset.py --randomization-tier 2
"""

import argparse
import os
import sys
import json
import time
import yaml
import numpy as np
import cv2
from datetime import datetime
from pathlib import Path

# Add module path for shared utilities
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
from shared.utils.tier_detection import detect_tier
from shared.utils.metrics import DatasetMetrics, GPUMetrics
from shared.utils.validation import validate_sc001_dataset_generation


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description='Exercise 2: Generate Synthetic Dataset')
    parser.add_argument('--num-images', type=int, default=100,
                       help='Number of images to generate (default: 100)')
    parser.add_argument('--output-dir', type=str, default='shared/datasets/generated_exercise2',
                       help='Output directory for generated dataset')
    parser.add_argument('--randomization-tier', type=int, choices=[1, 2, 3], default=1,
                       help='Domain randomization tier (1=lighting/texture, 2=+positions, 3=+physics)')
    parser.add_argument('--resolution', type=str, default='848x480',
                       help='Image resolution (default: 848x480)')
    parser.add_argument('--validate-only', action='store_true',
                       help='Only validate existing dataset, don\'t generate')
    parser.add_argument('--show-metrics', action='store_true',
                       help='Show performance metrics during generation')

    return parser.parse_args()


def create_output_directories(output_dir):
    """Create necessary output directories"""
    dirs = [
        os.path.join(output_dir, 'rgb'),
        os.path.join(output_dir, 'depth'),
        os.path.join(output_dir, 'segmentation'),
        os.path.join(output_dir, 'labels')
    ]

    for dir_path in dirs:
        os.makedirs(dir_path, exist_ok=True)
        print(f"ğŸ“ Created directory: {dir_path}")


def generate_sample_images(args, image_idx):
    """Generate sample RGB and depth images (simulated)"""
    width, height = map(int, args.resolution.split('x'))

    # Generate synthetic RGB image with simple patterns
    rgb_img = np.zeros((height, width, 3), dtype=np.uint8)

    # Add some random colored rectangles to simulate objects
    for _ in range(3):
        x = np.random.randint(0, width - 100)
        y = np.random.randint(0, height - 100)
        w = np.random.randint(50, 150)
        h = np.random.randint(50, 150)
        color = np.random.randint(0, 255, 3, dtype=np.uint8)
        cv2.rectangle(rgb_img, (x, y), (x + w, y + h), color.tolist(), -1)

    # Add some noise for realism
    noise = np.random.normal(0, 5, rgb_img.shape).astype(np.uint8)
    rgb_img = cv2.add(rgb_img, noise)

    # Generate corresponding depth image
    depth_img = np.zeros((height, width), dtype=np.float32)

    # Create depth zones (simulating different object distances)
    for i in range(5):
        x = np.random.randint(0, width - 50)
        y = np.random.randint(0, height - 50)
        w = np.random.randint(30, 200)
        h = np.random.randint(30, 200)
        depth_value = np.random.uniform(1.0, 10.0)  # meters
        depth_img[y:y+h, x:x+w] = depth_value

    # Convert to 16-bit PNG format (millimeters)
    depth_16bit = (depth_img * 1000).astype(np.uint16)

    return rgb_img, depth_16bit


def generate_segmentation_mask(rgb_img):
    """Generate semantic segmentation mask from RGB image (simulated)"""
    height, width = rgb_img.shape[:2]
    seg_mask = np.zeros((height, width), dtype=np.uint8)

    # Simple segmentation based on color regions
    # In real implementation, this would use Isaac Sim's semantic segmentation
    hsv = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2HSV)

    # Define some color ranges for different "classes"
    color_ranges = [
        ([0, 50, 50], [10, 255, 255], 1),    # Red objects -> class 1 (pallet)
        ([36, 50, 50], [70, 255, 255], 2),   # Green objects -> class 2 (box)
        ([25, 50, 50], [35, 255, 255], 3),   # Yellow objects -> class 3 (barrel)
        ([100, 50, 50], [130, 255, 255], 4), # Blue objects -> class 4 (forklift)
    ]

    for lower, upper, class_id in color_ranges:
        mask = cv2.inRange(hsv, np.array(lower), np.array(upper))
        seg_mask[mask > 0] = class_id

    return seg_mask


def generate_annotations(rgb_img, seg_mask, image_id):
    """Generate COCO format annotations"""
    annotations = []

    # Find contours in segmentation mask to create bounding boxes
    height, width = seg_mask.shape
    unique_classes = np.unique(seg_mask)
    unique_classes = unique_classes[unique_classes > 0]  # Exclude background

    for class_id in unique_classes:
        # Create mask for this class
        class_mask = (seg_mask == class_id).astype(np.uint8)

        # Find contours
        contours, _ = cv2.findContours(class_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            if len(contour) < 3:  # Need at least 3 points for a valid contour
                continue

            # Calculate bounding box
            x, y, w, h = cv2.boundingRect(contour)

            # Calculate area
            area = cv2.contourArea(contour)

            # Only add annotation if it's large enough
            if area > 100:  # Minimum area threshold
                annotation = {
                    "id": len(annotations),
                    "image_id": image_id,
                    "category_id": int(class_id),
                    "bbox": [int(x), int(y), int(w), int(h)],
                    "area": float(area),
                    "iscrowd": 0,
                    "segmentation": [contour.flatten().tolist()]  # Convert contour to polygon
                }
                annotations.append(annotation)

    return annotations


def apply_domain_randomization_tier1(rgb_img, depth_img, seg_mask):
    """Apply Tier 1 domain randomization (lighting and textures)"""
    # Randomize lighting intensity
    lighting_factor = np.random.uniform(0.7, 1.3)  # Â±30%
    rgb_img = np.clip(rgb_img.astype(np.float32) * lighting_factor, 0, 255).astype(np.uint8)

    # Randomize color temperature (simple approximation)
    temp_factor = np.random.uniform(0.9, 1.1, 3)  # RGB channels
    rgb_img = np.clip(rgb_img.astype(np.float32) * temp_factor, 0, 255).astype(np.uint8)

    # Add slight noise
    noise = np.random.normal(0, 2, rgb_img.shape).astype(np.float32)
    rgb_img = np.clip(rgb_img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    return rgb_img, depth_img, seg_mask


def apply_domain_randomization_tier2(rgb_img, depth_img, seg_mask):
    """Apply Tier 2 domain randomization (Tier 1 + object positions)"""
    # Apply Tier 1 randomization
    rgb_img, depth_img, seg_mask = apply_domain_randomization_tier1(rgb_img, depth_img, seg_mask)

    # Add position/rotation jitter effects (simulated)
    # In real implementation, this would affect 3D object positions in the scene

    # Add more noise
    noise = np.random.normal(0, 3, rgb_img.shape).astype(np.float32)
    rgb_img = np.clip(rgb_img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    # Simulate slight depth noise
    depth_noise = np.random.normal(0, 0.01, depth_img.shape).astype(np.float32)  # 1cm noise
    depth_img = np.clip(depth_img.astype(np.float32) + depth_noise * 1000, 0, 65535).astype(np.uint16)

    return rgb_img, depth_img, seg_mask


def apply_domain_randomization_tier3(rgb_img, depth_img, seg_mask):
    """Apply Tier 3 domain randomization (all features)"""
    # Apply Tier 2 randomization
    rgb_img, depth_img, seg_mask = apply_domain_randomization_tier2(rgb_img, depth_img, seg_mask)

    # Add more sophisticated effects
    # Simulate atmospheric effects, weather, etc.

    # Add more noise
    noise = np.random.normal(0, 4, rgb_img.shape).astype(np.float32)
    rgb_img = np.clip(rgb_img.astype(np.float32) + noise, 0, 255).astype(np.uint8)

    # Add more depth noise
    depth_noise = np.random.normal(0, 0.02, depth_img.shape).astype(np.float32)  # 2cm noise
    depth_img = np.clip(depth_img.astype(np.float32) + depth_noise * 1000, 0, 65535).astype(np.uint16)

    return rgb_img, depth_img, seg_mask


def save_dataset_image(rgb_img, depth_img, seg_mask, output_dir, image_id):
    """Save RGB, depth, and segmentation images"""
    # Save RGB image
    rgb_path = os.path.join(output_dir, 'rgb', f'{image_id:06d}.png')
    cv2.imwrite(rgb_path, cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR))

    # Save depth image
    depth_path = os.path.join(output_dir, 'depth', f'{image_id:06d}.png')
    cv2.imwrite(depth_path, depth_img)

    # Save segmentation image
    seg_path = os.path.join(output_dir, 'segmentation', f'{image_id:06d}.png')
    cv2.imwrite(seg_path, seg_mask)


def validate_dataset_quality(output_dir, num_images):
    """Validate the quality of generated dataset"""
    print("ğŸ” Validating dataset quality...")

    issues = []

    # Check if all required directories exist
    required_dirs = ['rgb', 'depth', 'segmentation']
    for dir_name in required_dirs:
        dir_path = os.path.join(output_dir, dir_name)
        if not os.path.exists(dir_path):
            issues.append(f"Missing directory: {dir_path}")
            continue

        # Count files in directory
        files = [f for f in os.listdir(dir_path) if f.endswith('.png')]
        if len(files) != num_images:
            issues.append(f"Directory {dir_name} has {len(files)} files, expected {num_images}")

    # Check image properties
    rgb_dir = os.path.join(output_dir, 'rgb')
    if os.path.exists(rgb_dir):
        sample_img_path = os.path.join(rgb_dir, '000000.png')
        if os.path.exists(sample_img_path):
            sample_img = cv2.imread(sample_img_path)
            if sample_img is None:
                issues.append("Could not read sample RGB image")
            else:
                print(f"   Sample image shape: {sample_img.shape}")

    print(f"   Quality validation: {'âœ… PASS' if not issues else 'âŒ FAIL'}")
    if issues:
        for issue in issues:
            print(f"     - {issue}")

    return len(issues) == 0, issues


def create_coco_annotations(output_dir, num_images, total_annotations):
    """Create COCO format annotations file"""
    print("ğŸ“„ Creating COCO annotations...")

    # Create categories
    categories = [
        {"id": 1, "name": "pallet", "supercategory": "object"},
        {"id": 2, "name": "cardboard_box", "supercategory": "object"},
        {"id": 3, "name": "barrel", "supercategory": "object"},
        {"id": 4, "name": "forklift", "supercategory": "vehicle"},
        {"id": 5, "name": "person", "supercategory": "human"},
        {"id": 6, "name": "shelf", "supercategory": "furniture"}
    ]

    # Create images list
    images = []
    for i in range(num_images):
        images.append({
            "id": i,
            "width": 848,  # Should match actual resolution
            "height": 480,
            "file_name": f"rgb/{i:06d}.png",
            "depth_file": f"depth/{i:06d}.png",
            "segmentation_file": f"segmentation/{i:06d}.png",
            "date_captured": datetime.now().isoformat()
        })

    # For this exercise, we'll create a mock annotations file
    # In real implementation, this would be populated with actual annotations
    annotations = []

    coco_data = {
        "info": {
            "description": "Synthetic Warehouse Dataset - Module 3 Exercise 2",
            "version": "1.0",
            "year": 2025,
            "contributor": "Physical AI Team",
            "date_created": datetime.now().isoformat()
        },
        "images": images,
        "annotations": annotations,
        "categories": categories
    }

    annotations_path = os.path.join(output_dir, "labels.json")
    with open(annotations_path, 'w') as f:
        json.dump(coco_data, f, indent=2)

    print(f"âœ… COCO annotations saved to {annotations_path}")
    return annotations_path


def show_performance_metrics(metrics):
    """Display performance metrics"""
    stats = metrics.get_statistics()
    print(f"ğŸ“Š Performance Metrics:")
    print(f"   Generation Rate: {stats['images_per_hour']:.0f} images/hour")
    print(f"   Elapsed Time: {stats['elapsed_time_sec']:.1f}s for {stats['total_images']} images")
    print(f"   Average: {stats['elapsed_time_sec']/stats['total_images']:.3f}s per image")


def main():
    """Main exercise execution"""
    print("=" * 60)
    print("Module 3 Exercise 2: Generate Synthetic Dataset")
    print("=" * 60)

    args = parse_arguments()

    # Show system metrics if requested
    if args.show_metrics:
        gpu_stats = GPUMetrics.get_gpu_stats()
        if gpu_stats:
            print(f"GPU: {gpu_stats['gpu_utilization_percent']:.1f}% utilization, "
                  f"{gpu_stats['memory_used_mb']:.0f}/{gpu_stats['memory_total_mb']:.0f} MB VRAM")
        print()

    # Check hardware tier
    tier = detect_tier()
    print(f"ğŸ¯ Hardware Tier: {tier.value.upper()} ({tier.name})")
    print(f"ğŸ“ˆ Target: Generate {args.num_images} images with domain randomization Tier {args.randomization_tier}")
    print()

    # Initialize metrics
    dataset_metrics = DatasetMetrics()
    dataset_metrics.start()

    if args.validate_only:
        print(f"ğŸ” Validation Mode: Validating dataset in {args.output_dir}")

        # Validate existing dataset
        is_valid, issues = validate_dataset_quality(args.output_dir, args.num_images)

        # Validate SC-001
        meets_criteria, message = validate_sc001_dataset_generation(dataset_metrics)
        print(f"SC-001 Validation: {'âœ… PASS' if meets_criteria else 'âŒ FAIL'} - {message}")

        return 0 if is_valid and meets_criteria else 1

    # Create output directories
    create_output_directories(args.output_dir)

    print(f"ğŸš€ Generating {args.num_images} synthetic images...")
    print(f"   Output directory: {args.output_dir}")
    print(f"   Resolution: {args.resolution}")
    print(f"   Randomization Tier: {args.randomization_tier}")
    print()

    # Apply domain randomization based on tier
    if args.randomization_tier == 1:
        apply_randomization = apply_domain_randomization_tier1
        print("âœ¨ Applying Tier 1 randomization: Lighting and texture variations")
    elif args.randomization_tier == 2:
        apply_randomization = apply_domain_randomization_tier2
        print("âœ¨ Applying Tier 2 randomization: Lighting, textures, object positions")
    else:
        apply_randomization = apply_domain_randomization_tier3
        print("âœ¨ Applying Tier 3 randomization: Comprehensive variations")

    print()

    # Generate images
    total_annotations = 0
    start_time = time.time()

    for i in range(args.num_images):
        # Generate base images
        rgb_img, depth_16bit = generate_sample_images(args, i)
        seg_mask = generate_segmentation_mask(rgb_img)

        # Apply domain randomization
        rgb_img, depth_16bit, seg_mask = apply_randomization(rgb_img, depth_16bit, seg_mask)

        # Generate annotations
        annotations = generate_annotations(rgb_img, seg_mask, i)
        total_annotations += len(annotations)

        # Save images
        save_dataset_image(rgb_img, depth_16bit, seg_mask, args.output_dir, i)

        # Record in metrics
        dataset_metrics.record_image()

        # Show progress
        if (i + 1) % max(1, args.num_images // 10) == 0 or i == 0:
            elapsed = time.time() - start_time
            rate = (i + 1) / elapsed * 3600 if elapsed > 0 else 0
            print(f"   Progress: {i + 1}/{args.num_images} images ({rate:.0f} images/hour)")

    generation_time = time.time() - start_time
    print(f"\nâœ… Dataset generation completed in {generation_time:.1f} seconds")
    print(f"ğŸ“ˆ Generated {args.num_images} images with {total_annotations} annotations")

    # Create COCO annotations
    annotations_path = create_coco_annotations(args.output_dir, args.num_images, total_annotations)

    # Validate dataset quality
    quality_valid, quality_issues = validate_dataset_quality(args.output_dir, args.num_images)

    # Validate SC-001: Generate 1000+ labeled images within 1 hour
    meets_sc001, sc001_message = validate_sc001_dataset_generation(dataset_metrics)
    print(f"\nSC-001 Validation: {'âœ… PASS' if meets_sc001 else 'âŒ FAIL'} - {sc001_message}")

    # Validate SC-007: This would require actual perception model training
    # For this exercise, we'll note that SC-007 relates to perception accuracy
    print(f"SC-007 Validation: ğŸ“Š Perception accuracy validation requires model training (see Chapter 4)")

    # FR validation
    fr003_passed = quality_valid  # FR-003: Generate synthetic labeled datasets
    fr004_passed = args.randomization_tier > 0  # FR-004: Domain randomization capabilities

    print(f"\nğŸ“‹ Functional Requirements:")
    print(f"   - FR-003 (Synthetic datasets): {'âœ… PASS' if fr003_passed else 'âŒ FAIL'}")
    print(f"   - FR-004 (Domain randomization): {'âœ… PASS' if fr004_passed else 'âŒ FAIL'}")

    # Performance metrics
    if args.show_metrics:
        show_performance_metrics(dataset_metrics)

    print(f"\nğŸ“ Dataset saved to: {args.output_dir}")
    print(f"ğŸ“„ Annotations saved to: {annotations_path}")

    if meets_sc001 and fr003_passed and fr004_passed:
        print(f"\nğŸ‰ Exercise 2 completed successfully!")
        print(f"You have generated {args.num_images} synthetic images with ground truth annotations")
        print(f"using domain randomization Tier {args.randomization_tier}.")
        return 0
    else:
        print(f"\nâš ï¸  Exercise 2 has issues that need to be resolved.")
        print(f"Check the validation messages above.")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)